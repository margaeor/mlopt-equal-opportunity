{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2e0cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-09-01\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"std\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JuMP, Gurobi, Random, Statistics, Combinatorics, LinearAlgebra\n",
    "using DataFrames, CSV, IterTools\n",
    "using Random\n",
    "using GLMNet, StatsBase\n",
    "using TimerOutputs\n",
    "using Gadfly\n",
    "using DataStructures\n",
    "using RDatasets\n",
    "\n",
    "const sparseTo = TimerOutput()\n",
    "\n",
    "seed = 2\n",
    "gurobi_env = Gurobi.Env()\n",
    "Random.seed!(seed)\n",
    "df_path = \"data/output/preprocessed.csv\"\n",
    "predictor_col = \"income_total\"\n",
    "normalization_type = \"std\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0dd0b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plotGroups (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function calc_r2(X, y, beta)\n",
    "    X = augment_X(X)\n",
    "    SSres = sum( (y .- X*beta).^2 )\n",
    "    SStot = sum( (y .- Statistics.mean(y)).^2 )\n",
    "    return 1-SSres/SStot\n",
    "end\n",
    "\n",
    "function calc_mse(X, y, beta)\n",
    "    X = augment_X(X)\n",
    "    n,p = size(X)\n",
    "    return sum((X*beta .- y).^2)/n\n",
    "end\n",
    "\n",
    "\n",
    "function grid_search(X, y, solver_func, error_func, groups, groupKs, error_strategy=\"Min\",train_val_ratio=0.7; params... )\n",
    "\n",
    "    # Split the data into training/validation\n",
    "    X_train, y_train, X_val, y_val = partitionTrainTest(X, y, train_val_ratio);\n",
    "    \n",
    "    # Create the grid (i.e. all the combinations of the given parameters)\n",
    "    param_names = keys(params)\n",
    "    param_combinations = [\n",
    "        Dict(param_names[i]=>p[i] for i in 1:length(param_names)) \n",
    "        for p in product([params[i] for i in keys(params)]...)\n",
    "    ]\n",
    "    \n",
    "    # Initialize variables used to hold validation information\n",
    "    error_multiplier = error_strategy == \"Min\" ? 1 : -1\n",
    "    best_error = Inf # We consider minimization\n",
    "    best_param_set = []\n",
    "    # println(\"----------------------------------------\")    \n",
    "    # println(param_combinations)\n",
    "    # println(\"----------------------------------------\")\n",
    "    # println(param_combinations)\n",
    "\n",
    "\n",
    "    # Iterate over all combinations of parameters\n",
    "    for param_comb in param_combinations\n",
    "        println(\"**********************\")\n",
    "        println(param_comb)\n",
    "        println(\"**********************\")\n",
    "        \n",
    "        # Optimize model and find optimal variables\n",
    "        global model_vars = solver_func(X_train,y_train, groups, groupKs;param_comb...)\n",
    "        \n",
    "        # Evaluate model error on validation set\n",
    "        if model_vars isa Tuple\n",
    "            error = error_multiplier*error_func(X_val, y_val, model_vars...)\n",
    "        else\n",
    "            error = error_multiplier*error_func(X_val, y_val, model_vars)\n",
    "        end\n",
    "        \n",
    "        # If error is better than the best error so far, keep track \n",
    "        # of the error and the params\n",
    "        if error < best_error\n",
    "            best_error = error \n",
    "            best_param_set = param_comb\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Retrain the model on the whole training set \n",
    "    # using the best set of params\n",
    "    model_vars = solver_func(X,y;best_param_set...)\n",
    "    \n",
    "    # Return the model variable and the best params\n",
    "    return model_vars, best_param_set\n",
    "end\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "function solve_holistic_regr(X,y, groups, groupKs;gamma,rho,k, outFlag = 1)\n",
    "    C = cor(X)\n",
    "    n,p = size(X)\n",
    "    X_aug = augment_X(X, true)\n",
    "    M = 10^5\n",
    "    # m = Model(with_optimizer(Gurobi.Optimizer, gurobi_env))\n",
    "    m = Model(with_optimizer(Gurobi.Optimizer))\n",
    "    set_optimizer_attribute(m, \"OutputFlag\", outFlag)\n",
    "    set_optimizer_attribute(m, \"PSDTol\", 1)\n",
    "    # set_optimizer_attribute(m, \"NonConvex\", 2)\n",
    "    set_optimizer_attribute(m, \"TimeLimit\", 60)\n",
    "    @variable(m, beta[1:(p+1)])\n",
    "    @variable(m, z[1:p],Bin)\n",
    "    @variable(m, t[1:p])\n",
    "    @objective(m, Min, 1/2*sum((X_aug*beta.-y).^2)+gamma*sum(t[i] for i=1:p))\n",
    "    @constraint(m, [i=1:p], t[i]>= beta[i])\n",
    "    @constraint(m, [i=1:p], t[i]>= -beta[i])\n",
    "    @constraint(m, [i=1:p], beta[i]<= M*z[i])\n",
    "    @constraint(m, [i=1:p], -M*z[i]<=beta[i])\n",
    "    @constraint(m, sum(z)<=k)\n",
    "\n",
    "    for (index, group) in enumerate(groups)\n",
    "        @constraint(m, sum(z[i] for i in group)<=groupKs[index])\n",
    "    end\n",
    "\n",
    "    for i in 1:p\n",
    "        for j in i+1:p\n",
    "            if abs(C[i,j]) > rho\n",
    "                @constraint(m, z[i]+z[j] <= 1)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    optimize!(m)\n",
    "    return JuMP.value.(beta)\n",
    "end\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "\n",
    "function printFeatures(betas, cols, isGroups = false; groups = [])    \n",
    "    if isGroups\n",
    "        for (index, group) in enumerate(groups)\n",
    "            println(\"Features selected from Group $(index) :\")  \n",
    "            \n",
    "            # sortperm(abs.(betas[2:end]), rev=true)\n",
    "            grpCounter = 0\n",
    "            tmpBetas = betas_holistic[sort!(collect(group))]\n",
    "            tmpCols = cols[sort!(collect(group))]\n",
    "            for i in sortperm(abs.(tmpBetas), rev=true)\n",
    "                if tmpBetas[i] != 0\n",
    "                    grpCounter = grpCounter + 1;\n",
    "                    println(\"$i - $(tmpBetas[i]) - $(tmpCols[i])\")\n",
    "                end\n",
    "            end\n",
    "            println(\"Total: $(grpCounter) Features from Group $(index)\")\n",
    "            println(\"--------------------------------------------------\")\n",
    "        end\n",
    "    else\n",
    "        THRESHOLD = 0.000001\n",
    "        grpCounter = 0\n",
    "\n",
    "        for i in sortperm(abs.(betas[2:end]), rev=true)\n",
    "            grpCounter = grpCounter + 1;\n",
    "\n",
    "            if abs(betas[i+1])<=THRESHOLD\n",
    "                grpCounter = grpCounter - 1;\n",
    "                continue\n",
    "            end\n",
    "            println(\"- $(cols[i]) : $(betas[i+1])\")\n",
    "        end\n",
    "        println(\"Total: $(grpCounter) Features\")\n",
    "        println(\"-----------------------------\")\n",
    "    end \n",
    "end\n",
    "\n",
    "function getMetrics(betas, X_train, y_train, X_test, y_test)    \n",
    "    r2_c = calc_r2(X_test, y_test, betas)\n",
    "    mse_c = calc_mse(X_test, y_test, betas)\n",
    "    println(\"r^2 train $(calc_r2(X_train, y_train, betas))\")\n",
    "    println(\"r^2 test $(calc_r2(X_test, y_test, betas))\")\n",
    "    println(\"mse train $(calc_mse(X_train, y_train, betas))\")\n",
    "    println(\"mse test $(calc_mse(X_test, y_test, betas))\")\n",
    "    return r2_c, mse_c\n",
    "end\n",
    "\n",
    "\n",
    "function iai2betas(learner, p)\n",
    "    beta0 = IAI.get_prediction_constant(learner)\n",
    "    betas = IAI.get_prediction_weights(learner)[1]\n",
    "    \n",
    "    features = string.(collect(keys(betas)))\n",
    "\n",
    "    beta_coeffs = zeros(p)\n",
    "    for i = 1:p\n",
    "        if \"x$i\" in features\n",
    "            beta_coeffs[i] = betas[Symbol(\"x$i\")]\n",
    "        end\n",
    "    end\n",
    "            \n",
    "    return [beta0 ; beta_coeffs]\n",
    "end\n",
    "\n",
    "function normalize_data(X, method=\"minmax\"; is_train=true)\n",
    "    X = copy(X)\n",
    "    if is_train\n",
    "        global nonzero_idx = findall([maximum(X[:,i])-minimum(X[:,i]) for i = 1:size(X,2)].>=0.01)\n",
    "        if method == \"std\"\n",
    "            global dt=fit(ZScoreTransform, X[:,nonzero_idx]; dims=1, center=true, scale=true)\n",
    "        elseif method == \"minmax\"\n",
    "            global dt=fit(UnitRangeTransform, X[:,nonzero_idx]; dims=1, unit=true)\n",
    "        end\n",
    "    end\n",
    "    X[:,nonzero_idx] = StatsBase.transform(dt, X[:,nonzero_idx])\n",
    "    \n",
    "    return X\n",
    "end\n",
    "\n",
    "\n",
    "function partitionTrainTest(X,y, at = 0.7, s=seed)\n",
    "    n = size(X,1)\n",
    "    idx = shuffle(1:n)\n",
    "    train_idx = view(idx, 1:floor(Int, at*n))\n",
    "    test_idx = view(idx, (floor(Int, at*n)+1):n)\n",
    "    return X[train_idx,:], y[train_idx], X[test_idx,:], y[test_idx]\n",
    "end\n",
    "\n",
    "function augment_X(X, flag = false)\n",
    "    if flag\n",
    "        return [X ones(size(X,1),1)]\n",
    "    else        \n",
    "        return [ones(size(X,1),1) X]\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function fit_lasso(X, y)\n",
    "    cv = glmnetcv(X, y);\n",
    "    id_best = argmin(cv.meanloss);\n",
    "    betas = [GLMNet.coef(cv);cv.path.a0[id_best]];\n",
    "    return betas\n",
    "end\n",
    "\n",
    "function solve_inner_problem(X,Y,s,γ)\n",
    "    indices = findall(s .> 0.5)\n",
    "    n = length(Y)\n",
    "    denom = 2*n\n",
    "    Xs = X[:, indices]\n",
    "    α = Y - Xs * (inv(I / γ + Xs' * Xs) * (Xs'* Y))\n",
    "    obj = dot(Y, α) / denom\n",
    "    tmp = X' * α\n",
    "    grad = -γ .* tmp .^ 2 ./ denom\n",
    "  return obj, grad\n",
    "end\n",
    "\n",
    "function sparse_regression(X,Y,k,γ,s0=[],is_binary=false; outFlag = 1, timeLimit = 60)\n",
    "    @timeit sparseTo \"Sparse Regression\" begin\n",
    "        m = Model(Gurobi.Optimizer)\n",
    "        set_optimizer_attribute(m, \"OutputFlag\", outFlag)\n",
    "        set_optimizer_attribute(m, \"TimeLimit\", timeLimit)\n",
    "        n,p = size(X)\n",
    "        \n",
    "        ###\n",
    "        # Step 1: Define the Variables:\n",
    "        ###\n",
    "        \n",
    "        if is_binary\n",
    "            @variable(m, s[1:p], Bin)\n",
    "            #@constraint(m, s[1:p] >= 0)\n",
    "        else\n",
    "            @variable(m, s[1:p]>=0)\n",
    "            @constraint(m, [i=1:p], s[i] <= 1)\n",
    "        end\n",
    "        \n",
    "        @variable(m, t >= 0)\n",
    "\n",
    "        ###\n",
    "        # Step 2: Set Up Constraints and Objective\n",
    "        ###\n",
    "        @constraint(m, sum(s) <= k)\n",
    "        # Initial solution: if none is provided, start at arbitrary point\n",
    "        if length(s0) == 0\n",
    "            s0 = zeros(p)\n",
    "            s0[1:k] .= 1\n",
    "        end\n",
    "        obj0, grad0 = solve_inner_problem(X,Y, s0, γ)\n",
    "        @constraint(m, t >= obj0 + dot(grad0, s - s0))\n",
    "        # Objective\n",
    "        @objective(m, Min, t)\n",
    "        \n",
    "        ###\n",
    "        # Step 3: Define the outer approximation function\n",
    "        ###\n",
    "        function outer_approximation(cb_data)\n",
    "            @timeit sparseTo \"Sparse Outter Approximation\" begin\n",
    "                s_val = []\n",
    "                for i = 1:p\n",
    "                    s_val = [s_val;callback_value(cb_data, s[i])]\n",
    "                end\n",
    "                @timeit sparseTo \"Sparse Inner Problem\" obj, grad = solve_inner_problem(X,Y, s_val, γ)\n",
    "                # add the cut: t >= obj + sum(∇s * (s - s_val))\n",
    "                offset = sum(grad .* s_val)\n",
    "                con = @build_constraint(t >= obj + sum(grad[j] * s[j] for j=1:p) - offset)    \n",
    "                MOI.submit(m, MOI.LazyConstraint(cb_data), con)\n",
    "            end\n",
    "        end\n",
    "        MOI.set(m, MOI.LazyConstraintCallback(), outer_approximation)\n",
    "\n",
    "        ###\n",
    "        # Step 4: Solve\n",
    "        ###\n",
    "        optimize!(m)\n",
    "        s_opt = JuMP.value.(s)\n",
    "        \n",
    "        s_nonzeros = []\n",
    "        # println(s_opt)\n",
    "        # println(\"t: $(JuMP.value(t))\")\n",
    "        if !is_binary\n",
    "            idxes = sortperm(s_opt, rev=true)\n",
    "            s = zeros(p)\n",
    "            s[idxes[1:k]] = ones(k)\n",
    "            s_nonzeros = idxes\n",
    "        else\n",
    "            s_nonzeros = findall(x -> x>0.5, s_opt)\n",
    "        end\n",
    "        β = zeros(p)\n",
    "        X_s = X[:, s_nonzeros]\n",
    "        # Formula for the nonzero coefficients\n",
    "        β[s_nonzeros] = γ * X_s' * (Y - X_s * ((I / γ + X_s' * X_s) \\ (X_s'* Y)))\n",
    "        \n",
    "        #return Dict(\"support\" => s_opt, \"coefs\" => β, \"selected_features\" => s_nonzeros)\n",
    "        return is_binary ? [0;β] : β \n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function plotGroups(betas, cols)\n",
    "\n",
    "    grp1betas   = Float64[]\n",
    "    grp1cols    = String[]\n",
    "    grp1Counter = 0\n",
    "    grp2betas   = Float64[]\n",
    "    grp2cols    = String[]\n",
    "    grp2Counter = 0\n",
    "    grp3betas   = Float64[]\n",
    "    grp3cols    = String[]\n",
    "    grp3Counter = 0\n",
    "    grp4betas   = Float64[]\n",
    "    grp4cols    = String[]\n",
    "    grp4Counter = 0\n",
    "    THRESHOLD = 0.000001\n",
    "\n",
    "    for i in sortperm(abs.(betas[2:end]), rev=true)\n",
    "        if abs(betas[i+1])>=THRESHOLD\n",
    "\n",
    "            if occursin(\"field\", cols[i])\n",
    "                println(\"$i - Group 1 : $(cols[i])\")\n",
    "                push!(grp1betas, betas[i+1])\n",
    "                push!(grp1cols, cols[i])\n",
    "                grp1Counter += 1\n",
    "            elseif occursin(\"occupation\", cols[i])\n",
    "                println(\"$i - Group 2 : $(cols[i])\")\n",
    "                push!(grp2betas, betas[i+1])\n",
    "                push!(grp2cols, cols[i])\n",
    "                grp2Counter += 1\n",
    "            elseif occursin(\"selfcare\", cols[i]) || occursin(\"sex\", cols[i]) || occursin(\"cognitive\", cols[i]) || occursin(\"race\", cols[i]) || occursin(\"parents\", cols[i])\n",
    "                println(\"$i - Group 3 : $(cols[i])\")\n",
    "                push!(grp3betas, betas[i+1])\n",
    "                push!(grp3cols, cols[i])\n",
    "                grp3Counter += 1\n",
    "            else\n",
    "                println(\"$i - Group 4 : $(cols[i])\")\n",
    "                push!(grp4betas, betas[i+1])\n",
    "                push!(grp4cols, cols[i])\n",
    "                grp4Counter += 1\n",
    "            end\n",
    "\n",
    "        end\n",
    "    end\n",
    "    println()\n",
    "    println(\"Group 1: $(grp1Counter) - Group 2: $(grp2Counter) - Group 3: $(grp3Counter) - Group 4: $(grp4Counter)\")\n",
    "    return grp1betas, grp1cols, grp2betas, grp2cols\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b9d23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246-element Vector{String}:\n",
       " \"age\"\n",
       " \"family_people_number\"\n",
       " \"household_people_number\"\n",
       " \"mortgage_second_payment\"\n",
       " \"own_children_number\"\n",
       " \"property_value\"\n",
       " \"workhours_week\"\n",
       " \"cognitive_difficulty_1.0\"\n",
       " \"cognitive_difficulty_2.0\"\n",
       " \"cognitive_difficulty_nan\"\n",
       " \"educational_attainment_1.0\"\n",
       " \"educational_attainment_2.0\"\n",
       " \"educational_attainment_3.0\"\n",
       " ⋮\n",
       " \"field_of_degree_56\"\n",
       " \"field_of_degree_57\"\n",
       " \"field_of_degree_59\"\n",
       " \"field_of_degree_60\"\n",
       " \"field_of_degree_61\"\n",
       " \"field_of_degree_62\"\n",
       " \"field_of_degree_64\"\n",
       " \"field_of_degree_nan\"\n",
       " \"num_degrees_0.0\"\n",
       " \"num_degrees_1.0\"\n",
       " \"num_degrees_2.0\"\n",
       " \"num_degrees_nan\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = DataFrame(CSV.File(df_path, header=1))\n",
    "names(df)\n",
    "dfSmall = df[shuffle(1:nrow(df))[1:10000], :]\n",
    "excluded_cols = [\n",
    "    \"earnings_total\",\n",
    "    \"income_interest_dividends_rental\",\n",
    "    \"income_retirement\",\n",
    "    \"income_all\",\n",
    "    \"income_social_security\",\n",
    "    \"income_supplementary_security\",\n",
    "    \"income_total\",\n",
    "    \"income_self_employment\",\n",
    "    \"income_household\",\n",
    "    \"income_to_poverty_ratio\",\n",
    "    \"income_public_assistance\",\n",
    "    \"income_family\",\n",
    "    \"income_wages_salary\",\n",
    "    \"monthly_owner_costs\",\n",
    "    \"gross_rent\",\n",
    "    \"person_number\",\n",
    "    \"rent_monthly\",\n",
    "    # \"property_value\",\n",
    "    \"mortgage_first_payment\",\n",
    "    \"gross_rent_pcnt_income\",\n",
    "    \"electricity_cost\",\n",
    "    \"cost_gas\",\n",
    "    \"cost_fuel\",\n",
    "    \"income_adjustment_factor\"\n",
    "]\n",
    "cols = filter(x -> x ∉ excluded_cols, names(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06a2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Matrix{Float32}(df[!, filter(x -> x != predictor_col, cols)]), df[!,predictor_col]\n",
    "X_train, y_train, X_test, y_test = partitionTrainTest(X, y, 0.7);\n",
    "X_train = normalize_data(X_train, normalization_type; is_train=true);\n",
    "X_test = normalize_data(X_test, normalization_type; is_train=false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9da1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2 train -0.4633598567300692\n",
      "r^2 test -0.45857745686285023\n",
      "mse train 7.714317983956681e9\n",
      "mse test 7.687799629535969e9\n",
      "Academic license - for non-commercial use only - expires 2022-09-01\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "Optimize a model with 2 rows, 247 columns and 477 nonzeros\n",
      "Model fingerprint: 0x89e9347a\n",
      "Variable types: 1 continuous, 246 integer (246 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-01, 2e+12]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+01, 4e+09]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "Warning: Model contains large rhs\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Presolve time: 0.01s\n",
      "Presolved: 2 rows, 247 columns, 477 nonzeros\n",
      "Variable types: 1 continuous, 246 integer (246 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 7 iterations, 0.01 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0    2          -    0.00000      -     -   15s\n",
      "H    0     0                    3.510735e+09    0.00000   100%     -   16s\n",
      "H    0     0                    3.509965e+09    0.00000   100%     -   18s\n",
      "     0     0    0.00000    0    3 3.5100e+09    0.00000   100%     -   26s\n",
      "     0     2    0.00000    0    3 3.5100e+09    0.00000   100%     -   26s\n",
      "   313   670    0.00000   42    3 3.5100e+09    0.00000   100%   1.9   40s\n",
      "   859  1151 7.9292e+08   99    2 3.5100e+09    0.00000   100%   1.7   54s\n",
      "  1677  1462 2.6087e+09  119    - 3.5100e+09    0.00000   100%   1.8   88s\n",
      "  2061  1700     cutoff  131      3.5100e+09    0.00000   100%   1.8  107s\n",
      "\n",
      "Cutting planes:\n",
      "  Lazy constraints: 239\n",
      "\n",
      "Explored 2354 nodes (4219 simplex iterations) in 125.94 seconds\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 3.50997e+09 3.51073e+09 \n",
      "\n",
      "Time limit reached\n",
      "Best objective 3.509965497204e+09, best bound 0.000000000000e+00, gap 100.0000%\n",
      "\n",
      "User-callback calls 5142, time in user-callback 125.56 sec\n",
      "r^2 train -0.33137782536313587\n",
      "r^2 test -0.32855895282820047\n",
      "mse train 7.018555179305087e9\n",
      "mse test 7.002504376652879e9\n",
      "- workhours_week : 15982.771309061063\n",
      "- property_value : 15473.166786652648\n",
      "- own_children_presence_nan : 11084.832289031785\n",
      "- occupation_code_1.0 : 9613.593980810641\n",
      "- age : 8156.882137097756\n",
      "- occupation_code_11.0 : 7456.630619647723\n",
      "- educational_attainment_5.0 : 7446.0177396643685\n",
      "- field_of_degree_nan : -7189.268733794851\n",
      "- occupation_code_nan : 6304.009257107742\n",
      "- occupation_code_8.0 : 5059.97495289058\n",
      "- field_of_degree_24 : 4387.251485194734\n",
      "- educational_attainment_6.0 : 4336.387314548821\n",
      "- occupation_code_4.0 : 4322.805948288212\n",
      "- worker_class_1.0 : 4310.27768687831\n",
      "- occupation_code_3.0 : 3882.5230409531737\n",
      "- household_family_type_1.0 : 3833.1006515757085\n",
      "- worker_class_7.0 : 3543.3469521986635\n",
      "- family_employment_status_2.0 : 3499.4565307551575\n",
      "- occupation_code_17.0 : 3458.0605581492027\n",
      "- occupation_code_2.0 : 3140.428694050412\n",
      "- field_of_degree_62 : 3099.4446456879195\n",
      "- field_of_degree_36 : 3063.743752296425\n",
      "- household_60_presence_0.0 : 3046.0742355446823\n",
      "- own_children_presence_4.0 : 2979.5544871536144\n",
      "- household_family_type_6.0 : 2903.870611571892\n",
      "- health_insurance_coverage_2.0 : -2616.551531647116\n",
      "- employment_status_1.0 : 2347.572479776007\n",
      "- english_language_nan : 2286.9389456613803\n",
      "- field_of_degree_55 : 2274.020885742216\n",
      "- field_of_degree_21 : 2229.777202945862\n",
      "- grade_level_attending_16.0 : -2093.3356306045303\n",
      "- occupation_code_13.0 : 1894.4474055912099\n",
      "- worker_class_5.0 : 1791.8281889658672\n",
      "- occupation_code_5.0 : 1765.3676098824697\n",
      "- meals_in_rent_2.0 : 1616.1333261315206\n",
      "- household_family_type_5.0 : 1434.874298926334\n",
      "- educational_attainment_3.0 : 1379.6092531092509\n",
      "- field_of_degree_23 : -1375.822242603369\n",
      "- field_of_degree_37 : 1254.793228045104\n",
      "- internet_highspeed_broadband_1.0 : 1119.0685420444295\n",
      "- food_stamps_yearly_1.0 : -919.5628882690548\n",
      "- marital_status_1.0 : 773.6842308887102\n",
      "- own_children_presence_3.0 : 650.2559485065599\n",
      "- worker_class_4.0 : -563.8505617886548\n",
      "- occupation_code_20.0 : 380.9497447477785\n",
      "- occupation_code_16.0 : -262.9119179172489\n",
      "- internet_satellite_1.0 : -234.73268609628653\n",
      "- occupation_code_21.0 : 191.78469458944875\n",
      "- telephone_service_8.0 : -173.72446256239112\n",
      "- field_of_degree_48 : 60.68475236352988\n",
      "Total: 50 Features\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "################################################################### \n",
    "## █▀ █▀█ ▄▀█ █▀█ █▀ █▀▀   █▀█ █▀▀ █▀▀ █▀█ █▀▀ █▀ █▀ █ █▀█ █▄░█  ##\n",
    "## ▄█ █▀▀ █▀█ █▀▄ ▄█ ██▄   █▀▄ ██▄ █▄█ █▀▄ ██▄ ▄█ ▄█ █ █▄█ █░▀█  ##\n",
    "###################################################################\n",
    "\n",
    "k = 50\n",
    "reset_timer!(sparseTo)\n",
    "betas_lasso = fit_lasso(X_train, y_train)\n",
    "\n",
    "betas_sparse = sparse_regression(X_train, y_train, k ,1/sqrt(size(X_train,1)), 1.0*(betas_lasso[1:end-1] .>= 0.5), true, timeLimit = 120)\n",
    "reset_timer!(sparseTo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9059af4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- workhours_week : 15982.771309061063\n",
      "- property_value : 15473.166786652648\n",
      "- own_children_presence_nan : 11084.832289031785\n",
      "- occupation_code_1.0 : 9613.593980810641\n",
      "- age : 8156.882137097756\n",
      "- occupation_code_11.0 : 7456.630619647723\n",
      "- educational_attainment_5.0 : 7446.0177396643685\n",
      "- field_of_degree_nan : -7189.268733794851\n",
      "- occupation_code_nan : 6304.009257107742\n",
      "- occupation_code_8.0 : 5059.97495289058\n",
      "- field_of_degree_24 : 4387.251485194734\n",
      "- educational_attainment_6.0 : 4336.387314548821\n",
      "- occupation_code_4.0 : 4322.805948288212\n",
      "- worker_class_1.0 : 4310.27768687831\n",
      "- occupation_code_3.0 : 3882.5230409531737\n",
      "- household_family_type_1.0 : 3833.1006515757085\n",
      "- worker_class_7.0 : 3543.3469521986635\n",
      "- family_employment_status_2.0 : 3499.4565307551575\n",
      "- occupation_code_17.0 : 3458.0605581492027\n",
      "- occupation_code_2.0 : 3140.428694050412\n",
      "- field_of_degree_62 : 3099.4446456879195\n",
      "- field_of_degree_36 : 3063.743752296425\n",
      "- household_60_presence_0.0 : 3046.0742355446823\n",
      "- own_children_presence_4.0 : 2979.5544871536144\n",
      "- household_family_type_6.0 : 2903.870611571892\n",
      "- health_insurance_coverage_2.0 : -2616.551531647116\n",
      "- employment_status_1.0 : 2347.572479776007\n",
      "- english_language_nan : 2286.9389456613803\n",
      "- field_of_degree_55 : 2274.020885742216\n",
      "- field_of_degree_21 : 2229.777202945862\n",
      "- grade_level_attending_16.0 : -2093.3356306045303\n",
      "- occupation_code_13.0 : 1894.4474055912099\n",
      "- worker_class_5.0 : 1791.8281889658672\n",
      "- occupation_code_5.0 : 1765.3676098824697\n",
      "- meals_in_rent_2.0 : 1616.1333261315206\n",
      "- household_family_type_5.0 : 1434.874298926334\n",
      "- educational_attainment_3.0 : 1379.6092531092509\n",
      "- field_of_degree_23 : -1375.822242603369\n",
      "- field_of_degree_37 : 1254.793228045104\n",
      "- internet_highspeed_broadband_1.0 : 1119.0685420444295\n",
      "- food_stamps_yearly_1.0 : -919.5628882690548\n",
      "- marital_status_1.0 : 773.6842308887102\n",
      "- own_children_presence_3.0 : 650.2559485065599\n",
      "- worker_class_4.0 : -563.8505617886548\n",
      "- occupation_code_20.0 : 380.9497447477785\n",
      "- occupation_code_16.0 : -262.9119179172489\n",
      "- internet_satellite_1.0 : -234.73268609628653\n",
      "- occupation_code_21.0 : 191.78469458944875\n",
      "- telephone_service_8.0 : -173.72446256239112\n",
      "- field_of_degree_48 : 60.68475236352988\n",
      "Total: 50 Features\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "getMetrics(betas_lasso, X_train, y_train, X_test, y_test)\n",
    "getMetrics(betas_sparse, X_train, y_train, X_test, y_test)\n",
    "printFeatures(betas_sparse, cols, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a35272e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: This copy of Interpretable AI software is for academic purposes only and not for commercial use.\n",
      "└ @ IAILicensing C:\\Users\\iai\\builds\\InterpretableAI\\SystemImage\\SysImgBuilder\\.julia\\packages\\IAILicensing\\P4JsQ\\src\\precompile.jl:19\n",
      "┌ Warning: Interpretable AI license expires soon: 2021-12-31T00:00:00. If you need to renew, please send us the following machine ID:\n",
      "│ f63e718242222a250dd4699d2f54be976b4a4a8ad66d7d0438302f91ca39381a\n",
      "└ @ IAILicensing C:\\Users\\iai\\builds\\InterpretableAI\\SystemImage\\SysImgBuilder\\.julia\\packages\\IAILicensing\\P4JsQ\\src\\precompile.jl:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295.629913 seconds (1.43 M allocations: 403.393 GiB, 19.13% gc time, 0.50% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "247-element Vector{Float64}:\n",
       " 60059.99600913882\n",
       "  7994.072227602028\n",
       "     0.0\n",
       " -3329.5414089227875\n",
       "  1142.955187192313\n",
       "  4280.969957877989\n",
       " 14951.892027106558\n",
       " 15139.704913461892\n",
       "     0.0\n",
       "     0.0\n",
       "     0.0\n",
       "  -886.0595993032262\n",
       "  -936.9741461778095\n",
       "     ⋮\n",
       "     0.0\n",
       "     0.0\n",
       "     0.0\n",
       "     0.0\n",
       "     0.0\n",
       "  3506.7434449093607\n",
       "     0.0\n",
       " -1601.875733013545\n",
       " -1601.875733013545\n",
       "  1501.376511513511\n",
       "   313.82759438703204\n",
       "     0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################\n",
    "## █ ▄▀█ █   █▀▀ █▀▀ ▄▀█ ▀█▀ █░█ █▀█ █▀▀   █▀ █▀▀ █░░ █▀▀ █▀▀ ▀█▀ █ █▀█ █▄░█   ##\n",
    "## █ █▀█ █   █▀░ ██▄ █▀█ ░█░ █▄█ █▀▄ ██▄   ▄█ ██▄ █▄▄ ██▄ █▄▄ ░█░ █ █▄█ █░▀█   ##\n",
    "#################################################################################\n",
    "\n",
    "@time begin\n",
    "    m = IAI.OptimalFeatureSelectionRegressor(\n",
    "        sparsity=70\n",
    "    )\n",
    "    res = IAI.fit!(m, X_train, y_train)\n",
    "end\n",
    "\n",
    "betas_iai = iai2betas(m, size(X,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb332c55",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: X_train not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X_train not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[7]:1",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1116"
     ]
    }
   ],
   "source": [
    "IAI.score(m, X_train, y_train)\n",
    "IAI.score(m, X_test, y_test)\n",
    "r2_c, mse_c = getMetrics(betas_iai, X_train, y_train, X_test, y_test)\n",
    "printFeatures(betas_iai, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15ad4e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 - Group 4 : workhours_week\n",
      "6 - Group 4 : property_value\n",
      "1 - Group 4 : age\n",
      "15 - Group 4 : educational_attainment_5.0\n",
      "135 - Group 4 : own_children_presence_nan\n",
      "102 - Group 2 : occupation_code_1.0\n",
      "214 - Group 1 : field_of_degree_24\n",
      "60 - Group 4 : household_60_presence_0.0\n",
      "112 - Group 2 : occupation_code_11.0\n",
      "5 - Group 4 : own_children_number\n",
      "110 - Group 2 : occupation_code_9.0\n",
      "16 - Group 4 : educational_attainment_6.0\n",
      "109 - Group 2 : occupation_code_8.0\n",
      "31 - Group 4 : family_employment_status_2.0\n",
      "240 - Group 1 : field_of_degree_62\n",
      "132 - Group 4 : own_children_presence_2.0\n",
      "3 - Group 4 : household_people_number\n",
      "125 - Group 2 : occupation_code_24.0\n",
      "222 - Group 1 : field_of_degree_36\n",
      "119 - Group 2 : occupation_code_18.0\n",
      "124 - Group 2 : occupation_code_23.0\n",
      "234 - Group 1 : field_of_degree_55\n",
      "201 - Group 4 : worker_class_7.0\n",
      "115 - Group 2 : occupation_code_14.0\n",
      "211 - Group 1 : field_of_degree_21\n",
      "42 - Group 4 : family_presence_age_children_4.0\n",
      "105 - Group 2 : occupation_code_4.0\n",
      "108 - Group 2 : occupation_code_7.0\n",
      "104 - Group 2 : occupation_code_3.0\n",
      "116 - Group 2 : occupation_code_15.0\n",
      "61 - Group 4 : household_60_presence_1.0\n",
      "40 - Group 4 : family_presence_age_children_2.0\n",
      "18 - Group 4 : employment_status_1.0\n",
      "121 - Group 2 : occupation_code_20.0\n",
      "117 - Group 2 : occupation_code_16.0\n",
      "26 - Group 4 : english_language_2.0\n",
      "195 - Group 4 : worker_class_1.0\n",
      "183 - Group 4 : tablet_2.0\n",
      "242 - Group 1 : field_of_degree_nan\n",
      "243 - Group 4 : num_degrees_0.0\n",
      "198 - Group 4 : worker_class_4.0\n",
      "244 - Group 4 : num_degrees_1.0\n",
      "64 - Group 4 : household_family_type_1.0\n",
      "113 - Group 2 : occupation_code_12.0\n",
      "229 - Group 1 : field_of_degree_50\n",
      "27 - Group 4 : english_language_3.0\n",
      "223 - Group 1 : field_of_degree_37\n",
      "200 - Group 4 : worker_class_6.0\n",
      "57 - Group 4 : health_insurance_coverage_1.0\n",
      "58 - Group 4 : health_insurance_coverage_2.0\n",
      "4 - Group 4 : mortgage_second_payment\n",
      "103 - Group 2 : occupation_code_2.0\n",
      "93 - Group 4 : marital_status_1.0\n",
      "197 - Group 4 : worker_class_3.0\n",
      "23 - Group 4 : employment_status_6.0\n",
      "85 - Group 4 : internet_highspeed_broadband_2.0\n",
      "12 - Group 4 : educational_attainment_2.0\n",
      "11 - Group 4 : educational_attainment_1.0\n",
      "133 - Group 4 : own_children_presence_3.0\n",
      "20 - Group 4 : employment_status_3.0\n",
      "97 - Group 4 : marital_status_5.0\n",
      "213 - Group 1 : field_of_degree_23\n",
      "56 - Group 4 : grade_level_attending_nan\n",
      "165 - Group 4 : school_enrollment_1.0\n",
      "62 - Group 4 : household_60_presence_2.0\n",
      "13 - Group 4 : educational_attainment_3.0\n",
      "245 - Group 4 : num_degrees_2.0\n",
      "154 - Group 3 : race_detailed_1_8.0\n",
      "172 - Group 3 : sex_1.0\n",
      "173 - Group 3 : sex_2.0\n",
      "\n",
      "Group 1: 9 - Group 2: 16 - Group 3: 3 - Group 4: 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([4582.1452768966055, 3506.7434449093607, 3025.3137271144774, 2550.9274067815963, 2370.3705758360147, -1601.875733013545, 1351.018776244861, 1339.5927214813719, -801.5727990294071], [\"field_of_degree_24\", \"field_of_degree_62\", \"field_of_degree_36\", \"field_of_degree_55\", \"field_of_degree_21\", \"field_of_degree_nan\", \"field_of_degree_50\", \"field_of_degree_37\", \"field_of_degree_23\"], [6025.3784086965425, 4411.580947813583, -4022.5310915497516, 3878.713114954981, -3079.5507978354317, -2629.525226272623, -2588.0026716151206, -2508.2949637983775, 2263.5624336064407, -2232.866384351082, 2170.7133869133454, -2160.942489764354, -1916.20236766738, -1891.642854351145, -1403.45207422719, 1120.4091153429695], [\"occupation_code_1.0\", \"occupation_code_11.0\", \"occupation_code_9.0\", \"occupation_code_8.0\", \"occupation_code_24.0\", \"occupation_code_18.0\", \"occupation_code_23.0\", \"occupation_code_14.0\", \"occupation_code_4.0\", \"occupation_code_7.0\", \"occupation_code_3.0\", \"occupation_code_15.0\", \"occupation_code_20.0\", \"occupation_code_16.0\", \"occupation_code_12.0\", \"occupation_code_2.0\"])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grp1betas, grp1cols, grp2betas, grp2cols = plotGroups(betas_iai, cols)\n",
    "Gadfly.push_theme(:dark)\n",
    "set_default_plot_size(10cm, 10cm)\n",
    "\n",
    "# grp1betas, grp1cols, grp2betas, grp2cols = plotGroups(betas_iai, cols)\n",
    "\n",
    "# Gadfly.push_theme(:dark)\n",
    "# set_default_plot_size(60cm, 60cm)\n",
    "\n",
    "# Gadfly.plot(grp1betas, x=\"Chest\", y=\"Count\", Geom.bar)\n",
    "\n",
    "# plot(dataset(\"MASS\", \"nlschools\"), x=\"IQ\", y=\"Lang\", color=\"COMB\",\n",
    "#             Geom.point, Geom.smooth(method=:lm), Guide.colorkey(\"Multi-Grade\"))\n",
    "\n",
    "# set_default_plot_size(60cm, 300cm)\n",
    "# vstack(p1, p2)\n",
    "# plot(p1, p2)\n",
    "# theme(:dark)\n",
    "\n",
    "# p1 = Gadfly.plot([sin,cos], 0, 2pi)\n",
    "# p2 = Gadfly.plot((x,y)->sin(x)+cos(y), 0, 2pi, 0, 2pi)\n",
    "# p3 = Gadfly.spy(ones(33)*sin.(0:(pi/16):2pi)' + cos.(0:(pi/16):2pi)*ones(33)')\n",
    "# hstack(p1,p2,p3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d315b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: Gadfly not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Gadfly not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[2]:2",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1116"
     ]
    }
   ],
   "source": [
    "# grp1betas, grp1cols, grp2betas, grp2cols = plotGroups(betas_iai, cols)\n",
    "Gadfly.push_theme(:dark)\n",
    "set_default_plot_size(20cm, 20cm)\n",
    "\n",
    "dfsample = DataFrame(A = grp1betas, B = grp1cols)\n",
    "p1 = Gadfly.plot(dfsample,\n",
    "    x=:B,\n",
    "    y=:A,\n",
    "    Geom.bar(orientation = :vertical),\n",
    "    Theme(\n",
    "        #bar_spacing=5mm\n",
    "    )\n",
    ")\n",
    "\n",
    "dfsample = DataFrame(A = grp2betas, B = grp2cols)\n",
    "p2 = Gadfly.plot(dfsample,\n",
    "    x=:B,\n",
    "    y=:A,\n",
    "    Geom.bar(orientation = :vertical),\n",
    "    Theme(\n",
    "        #bar_spacing=5mm\n",
    "    )\n",
    ")\n",
    "\n",
    "hstack(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9dfd5c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-09-05\n",
      "[1.0, -0.0, 1.0, 1.0, -0.0, 1.0, -0.0, 1.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, 0.0, 0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, 1.0, 1.0, 1.0, -0.0, 1.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, 1.0, -0.0, 1.0, 1.0, -0.0, 1.0, 1.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, 1.0, -0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, 1.0, 1.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, 1.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, 1.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, 1.0, -0.0, 1.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 1.0, 1.0, -0.0, -0.0]\n",
      "t: 4.868003110097021e6\n",
      "r^2 train -8.269812628554263\n",
      "r^2 train -1.006581963519777\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "## █░█ █▀█ █░░ █ █▀ ▀█▀ █ █▀▀   █▀█ █▀▀ █▀▀ █▀█ █▀▀ █▀ █▀ █ █▀█ █▄░█  ##\n",
    "## █▀█ █▄█ █▄▄ █ ▄█ ░█░ █ █▄▄   █▀▄ ██▄ █▄█ █▀▄ ██▄ ▄█ ▄█ █ █▄█ █░▀█  ##\n",
    "########################################################################\n",
    "\n",
    "seed = 4\n",
    "Nhol = 5000\n",
    "grpAll = Set(1:length(cols))\n",
    "fodInit = 205; fodEnd = 241\n",
    " # FIELD OF DEGREE GROUP ------------------------------- 1\n",
    "grp1 = Set(fodInit:fodEnd)\n",
    "socInit = 102; socEnd = 127\n",
    "# OCCUPATION CODE GROUP -------------------------------- 2\n",
    "grp2 = Set(socInit:socEnd) \n",
    "# A-PRIORI TRAITS (Sex, Race, Disabilities) GROUP ------ 3\n",
    "# SEX GROUP\n",
    "sexInit = 173; sexEnd = 175;\n",
    "sexGrp = Set(sexInit:sexEnd)\n",
    "# DISABILITIES GROUP\n",
    "disInit1 = 9; disEnd1 = 11;\n",
    "disInit2 = 170; disEnd2 = 172;\n",
    "disGrp = union(Set(disInit1:disEnd1), Set(disInit2:disEnd2))\n",
    "# RACE GROUP\n",
    "raceInit = 137; raceEnd = 163;\n",
    "raceGrp = Set(raceInit:raceEnd)\n",
    "# UNITE ALL\n",
    "grp3 = union(raceGrp, disGrp, sexGrp)\n",
    "grp4 = setdiff(grpAll, union(grp1, grp2, grp3))\n",
    "\n",
    "groups = [grp1 grp2 grp3 grp4]\n",
    "groupKs = [20 25 30 25]\n",
    "\n",
    "global indexArr = Int[]\n",
    "global nzArr = Int[]\n",
    "global rsqArr = Float64[]\n",
    "\n",
    "# for seed = [19]\n",
    "for seed = 15:25\n",
    "cols = filter(x -> x ∉ excluded_cols, names(df))\n",
    "\n",
    "    Random.seed!(seed)\n",
    "    df2 = df[shuffle(1:nrow(df))[1:Nhol], :]\n",
    "    X, y = Matrix{Float32}(df2[!, filter(x -> x != predictor_col, cols)]), df2[!,predictor_col]\n",
    "    X_train, y_train, X_test, y_test = partitionTrainTest(X, y, 0.7);\n",
    "    X_train = normalize_data(X_train, normalization_type; is_train=true);\n",
    "    X_test = normalize_data(X_test, normalization_type; is_train=false);\n",
    "\n",
    "    try\n",
    "        betas_holistic, params_holistic = grid_search(X_train, y_train, solve_holistic_regr, calc_r2,  groups, groupKs , \"Max\", 0.7; gamma=[0.5 1], rho=[0.5 0.7], k=[50 75])\n",
    "        println(\"Workeed -- $(seed)\")\n",
    "        nzeros = (length(betas_holistic[betas_holistic .!= 0]))\n",
    "        println(\"NONZEROS = $(length(betas_holistic[betas_holistic .!= 0]))\")\n",
    "        push!(indexArr, seed)\n",
    "        push!(nzArr, nzeros)\n",
    "\n",
    "        betas_holistic2 = [betas_holistic[end] ; betas_holistic[1:end-1]]\n",
    "        r2_c = calc_r2(X_test, y_test, betas_holistic2)\n",
    "        push!(rsqArr, r2_c)\n",
    "    catch\n",
    "        println(\"Error (probably psd) -- $(seed)\")\n",
    "    end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9aa4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################### \n",
    "printFeatures(betas_holistic, cols, true; groups)\n",
    "###############################################################################################\n",
    "betas_holistic2 = [betas_holistic[end] ; betas_holistic[1:end-1]]\n",
    "\n",
    "r2_c = calc_r2(X_test, y_test, betas_holistic2)\n",
    "mse_c = calc_mse(X_test, y_test, betas_holistic2)\n",
    "\n",
    "for i in 1:length(cols)\n",
    "    println(\"$i - $(cols[i])\")\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
